---
title: "BI EDA"
author: "Jesse Normand"
output: 
  html_document:
    
   toc: true
   toc_float: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(correlationfunnel)
library(tidyverse)
library(DataExplorer)
library(psych)
library(factoextra)
library(FactoMineR)



dat <- read.csv("student_list.csv")
dat2 <- read.csv("enrollment.csv")

dat_merg <- merge(dat, dat2, by =c ("Student_SK"))

```

## OVERVIEW

SNHU is in the business of providing higher learning at scale. Although
the goal and mission of student success are at the forefront, it is also
imperative that the business component is running at peak performance to
ensure the ultimate goal can be accomplished.

## Objective

The goal of my analysis is to determine if the data shows us areas where
we can potentially maximize our efforts related to student success and
maintaining enrollment.

## Method

The first phase of this analysis will focus on cleaning the data,
understanding our data, and quantifying and qualifying the data.

We will use correlation and correspondence analysis to provide insight
into inputs we can focus on to ensure we are meeting our objective.

To keep the clarity of this report simple and focused on the business
logic side of the equation vs. the underlying programming, I will show
output only and will leave a link below to the code for those who may
want to review.

<https://github.com/JesseNormand/snhu/blob/main/SNHU_EDA.Rmd>

## EDA

Let's begin by looking at our data to determine the quality of the data
as well as to begin assessing cleaning and shaping the data if needed.

We will plot out the data for a visual inspection.

With this plot, we get a quick feel for the type of data we have, and
the overall completeness. The glaring observation here is that we have
some missing values.

```{r}
introduce(dat_merg)

plot_intro(dat_merg)
```

Let's take a closer look by column.

Normally, I would reach out to stakeholders to gather additional
information related to missing data; however, since that is not an
option for this demonstration, I will remove the NAs. We could look at
the option to impute a mean for the "HasPersistance", but since we are
working with a binary, the best option here given we have ample data to
work with, is to remove the NAs.

```{r warning=FALSE}
colSums(is.na(dat_merg))
```

Ok, we are back on track.

```{r warning=FALSE}
dat_merg <- na.omit(dat_merg)
plot_missing(dat_merg)

```

Let's take another look at the data. For this analysis, the data looks
adequate to work; however, before moving on, we will trim the mean for
"CourseAverageGrade."I noticed that there is a large frequency spike in
scores at 100%. I would want to verify if that information is accurate.
For this analysis, we will trim the max and min to balance out the mean
and move forward.

```{r warning=FALSE}
describeBy(dat_merg)

```

```{r}
dat_merg$CourseAverageGrade <-  mean(dat_merg$CourseAverageGrade, trim = 0.1)
print(mean(dat_merg$CourseAverageGrade))
```

## Contingency Table

To test my correlation theory among variables I will create a simple
contingency table, and run a chi-square test.

Great, the chi-square test tells us we have independence between these
variables, we have variation in our data greater than the expected
observations.

```{r}
dat_merg_dummy <-na.omit(dat_merg) %>%
  binarize(n_bins = 5, one_hot = TRUE)
multi_table <-  xtabs(~ CurrentLearnerSegment + HasPersistenceIntoNextTerm + Success,  data = dat_merg)

multi_table2 <-  ftable(multi_table)

multi_table2

chisq.test(multi_table2)

```

## Correlation Plot

Continuing with our analysis, let's drill down on correlations.

Ok, my focus here is on the "HasPersitenceIntoNextTerm" variable.
Ideally, a high volume of students continuing through the program term
after term will be a litmus test for the overall success of the system.

In general, I see what I would expect here with positive grades,
success, etc correlating with a positive persistence score.

My attention however is drawn to the negative correlation in the "Other"
segment of "CurrentLearnerSegment" has on our response variable.

While it is not a large negative variance, it does stand out from the
other segments, and will be worth exploring.

```{r warning=FALSE}
dat_merg_dummy <-na.omit(dat_merg) %>%
  binarize(n_bins = 5, one_hot = TRUE)


dat_merg_dummy <- dat_merg_dummy %>%
  correlate(HasPersistenceIntoNextTerm__1 )

dat_merg_dummy %>%
  plot_correlation_funnel(interactive = TRUE)
```

## Correspondence Analysis

Next, we will run a simple correspondence analysis to further drill down
any patterns or relationships in our variables.

Interesting. "Business to Consumer(Retail) Course Work Only" and "Latin
America" show a separation from the rest of our data. "Persistence_No"
and "Unknown" trend towards these variables as well.

```{r warning=FALSE, include=FALSE}
cont_table <- read.csv("cont_table.csv", header = TRUE)


cont_table_ca <- as.table(as.matrix(cont_table))


row.names(cont_table) <- c('Business to Consumer(Retail)',
                           'Business to Consumer(Retail) Course Work Only',
                           'Corporate Partner',
                           'Guild',
                           'Latin America'
                           
                           
)

cont_table$Row.Labels <- NULL
CA(cont_table, ncp = 5, graph = TRUE)
```

We can also see that "Business to Consumer(Retail) Course Work Only" is
having the most variance impact in Dimension 1.

```{r warning=FALSE}
res_ca <- CA(cont_table, graph = FALSE)
row_values <- get_ca_row(res_ca)
row_values$contrib
```

Finally, we will run an asymmetric biplot to quantify the relational
variance these variables have.

And there we have it, the theory we began to develop related to the
"Other" consumer retail segment is also showing up in our biplot
indicating "Business to Consumer(Retail) Course Work Only", and
"Persistence_No" have a close information impact on eachother.

```{r}
fviz_ca_biplot(res_ca, 
               map ="rowprincipal", arrow = c(TRUE, TRUE),
               repel = TRUE)

```

## Summary

Our objective was to determine if the data would show us areas where we
can potentially maximize our efforts related to student success and
maintaining enrollment.

We discovered that there was a negative correlation with a segment of
the "CurrentLearnerSegment."

Using correspondence analysis, we were able to show a justification for
continuing analysis into a subset of the "CurrentLearnerSegment" -
"Business to Consumer(Retail) Course Work Only", and "Latin America."

Exploring this business channel segment would be a beginning objective
for me to determine if this segment can be improved.
